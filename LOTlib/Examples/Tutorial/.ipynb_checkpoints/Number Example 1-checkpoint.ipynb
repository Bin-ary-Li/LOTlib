{
 "metadata": {
  "name": "",
  "signature": "sha256:382abec3f72b5609f666081525de4d4f833c312fed151956933c24e7188effa9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Number Example\n",
      "--------------\n",
      "\n",
      "#### this is a smaller heading\n",
      "\n",
      "Given as input a set of integers taken from the domain, a learner should be able to learn the rule that was used to generate this subset of the domain.\n",
      "\n",
      "The *domain* is the (finite) set of numbers that we are considering. For this example, we'll consider the domain as being the set of integers from 1 through 100. \n",
      "\n",
      "A *rule* maps an input set of numbers to an output set of numbers. These will be written in the form:\n",
      "\\begin{equation} n_{input} \\longrightarrow f(n)_{output} \\end{equation}\n",
      "\n",
      "\n",
      "For example, on input \n",
      ">{2, 4, 8, 10, 12, 14, 20}\n",
      "\n",
      "a learner should be able to recognize that these are only even numbers. In other words, the rule for generating these numbers is:\n",
      "\\begin{equation} n \\longrightarrow n^{2} \\end{equation}\n",
      "\n",
      "Where the left hand "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "%matplotlib inline\n",
      "from math import log\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "from LOTlib import lot_iter\n",
      "from LOTlib.Grammar import Grammar\n",
      "from LOTlib.Hypotheses.LOTHypothesis import *\n",
      "from LOTlib.Evaluation.Eval import *\n",
      "from LOTlib.Miscellaneous import logsumexp, exp\n",
      "\n",
      "from LOTlib.Examples.Tutorial.number import NumberGameExpression\n",
      "\n",
      "\n",
      "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 2 : Create grammar ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
      "# - Rules in our grammar map between sets of integers in our domain                     #\n",
      "# - E.g. \"3n+1\" maps to { 1, 4, 7, 10, ... }                                            #\n",
      "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
      "grammar = Grammar()\n",
      "grammar.add_rule('START', '', ['EXPR'], 1)\n",
      "# grammar.add_rule('EXPR', 'times_', ['EXPR', 'EXPR'], 1)\n",
      "grammar.add_rule('EXPR', 'plus_', ['EXPR', 'EXPR'], 1)\n",
      "# grammar.add_rule('EXPR', 'minus_', ['EXPR', 'EXPR'], 1)\n",
      "grammar.add_rule('EXPR', 'pow_', ['EXPR', 'EXPR'], 1)\n",
      "\n",
      "# Converted to digits so python can evaluate them\n",
      "grammar.add_rule('EXPR', 'n', None, 10)\n",
      "for i in range(1, 3):\n",
      "    grammar.add_rule('EXPR', str(i), None, (10-i)/2)\n",
      "\n",
      "\n",
      "#~~~~~~~~~~~~~~~~~~~~~~~~ 3 : Generate hypotheses for data ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
      "# Edit these parameters\n",
      "num_iters = 5000\n",
      "data = [3, 9, 17]\n",
      "domain = 100\n",
      "noise = 0.9\n",
      "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
      "'''\n",
      "from LOTlib.Inference.MetropolisHastings import MHSampler\n",
      "\n",
      "hypotheses = set()\n",
      "h0 = NumberGameExpression(grammar, domain=domain, noise=noise)\n",
      "for h in MHSampler(h0, data, steps=num_iters):\n",
      "    #print h   # with this you can see how hill climbing moves towards maxima\n",
      "    hypotheses.add(h)\n",
      "'''\n",
      "\n",
      "hypotheses = set()\n",
      "for _ in lot_iter(xrange(num_iters)):       # You can ctrl+C to exit this loop\n",
      "    t = NumberGameExpression(grammar, domain=domain, noise=noise)\n",
      "    t.compute_posterior(data)               # Get prior, likelihood, posterior\n",
      "    hypotheses.add(t)\n",
      "\n",
      "# exp(posterior_score) is proportional to posterior probability, so we estimate normalizing\n",
      "# constant Z like so:\n",
      "Z = logsumexp([h.posterior_score for h in hypotheses])\n",
      "\n",
      "\n",
      "#~~~~~~~~~~~~ printing prior, likelihood, & normalized posterior score ~~~~~~~~~~~~~~~~~#\n",
      "# for h in sorted(hypotheses, key=lambda x: x.posterior_score):\n",
      "#     print h.prior, h.likelihood, exp(h.posterior_score - Z), h\n",
      "\n",
      "print str(num_iters) + ' number of iterations'\n",
      "print str(len(hypotheses)) + ' hypotheses in total'\n",
      "\n",
      "\n",
      "#~~~~~~~~~ graph p(y in C | d) as a function of y in domain (see figs 3,4,9) ~~~~~~~~~~~#\n",
      "# - NOTE: this does not calculate p(y in C | d);  change to describe what it does calc. #\n",
      "predictive_dist = [0.]*domain\n",
      "\n",
      "# Calculate chance of sampling for each item in domain\n",
      "for q in range(domain):\n",
      "    # Sum p(q|h) * p(h|D) for all hypotheses h\n",
      "    for h in hypotheses:\n",
      "        posterior = h.posterior_score - Z\n",
      "        likelihood = h.compute_likelihood([q+1])\n",
      "        predictive_dist[q] += exp(posterior + likelihood)\n",
      "        # if (likelihood / posterior) > 10:\n",
      "        #     print '\\nh: '+str(h)+'\\nq: '+str(q)+'\\npost: '+str(posterior)+'\\nlike: '+str(\n",
      "        #         likelihood)+'\\n~~~~~~~~~~'\n",
      "\n",
      "fig, ax = plt.subplots()\n",
      "rects = plt.bar(range(1,domain+1), predictive_dist)\n",
      "\n",
      "plt.xlabel('Domain (from 1 to '+str(domain)+')')\n",
      "plt.ylabel('Probability of sampling this value')\n",
      "plt.title('This graph needs a title!')\n",
      "\n",
      "plt.show()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}